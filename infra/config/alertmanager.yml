global:
  # Global configuration for all alerts
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@antibot-security.com'
  smtp_auth_username: '${SMTP_USERNAME}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  
  # Slack configuration
  slack_api_url: '${SLACK_WEBHOOK_URL}'

# Templates for custom alert messages
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route configuration
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'
  
  routes:
    # Critical security alerts - immediate notification
    - match:
        severity: critical
        service: security
      receiver: 'security-team-critical'
      group_wait: 10s
      repeat_interval: 30m
      continue: true
    
    # ML/AI alerts for data science team
    - match:
        service: ml-risk-engine
      receiver: 'ml-team'
      group_wait: 1m
      repeat_interval: 2h
      continue: true
    
    # Infrastructure alerts for DevOps team
    - match_re:
        service: 'redis|elasticsearch|vault|system'
      receiver: 'devops-team'
      group_wait: 2m
      repeat_interval: 1h
      continue: true
    
    # Business metrics for leadership
    - match:
        service: business
      receiver: 'business-team'
      group_wait: 5m
      repeat_interval: 6h
    
    # Application performance alerts
    - match:
        service: application
      receiver: 'engineering-team'
      group_wait: 3m
      repeat_interval: 2h

# Alert receiver configurations
receivers:
  - name: 'default-receiver'
    webhook_configs:
      - url: '${DEFAULT_WEBHOOK_URL}'
        send_resolved: true
        title: 'Anti-Bot Security Alert'
        text: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.service }}
          {{ end }}

  - name: 'security-team-critical'
    slack_configs:
      - api_url: '${SECURITY_SLACK_WEBHOOK_URL}'
        channel: '#security-alerts'
        color: 'danger'
        title: 'üö® CRITICAL Security Alert üö®'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Service:* {{ .Labels.service }}
          *Time:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
        actions:
          - type: button
            text: 'View in Grafana'
            url: '${GRAFANA_URL}/d/security-dashboard'
          - type: button
            text: 'View Logs'
            url: '${KIBANA_URL}/app/discover'
    
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_SECURITY_KEY}'
        description: 'Critical security alert in anti-bot system'
        severity: 'critical'
    
    email_configs:
      - to: 'security-team@company.com'
        subject: '[CRITICAL] Anti-Bot Security Alert'
        body: |
          Critical security alert detected:
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
          
          Please investigate immediately.

  - name: 'ml-team'
    slack_configs:
      - api_url: '${ML_SLACK_WEBHOOK_URL}'
        channel: '#ml-monitoring'
        color: 'warning'
        title: 'ü§ñ ML Model Alert'
        text: |
          {{ range .Alerts }}
          *Model Issue:* {{ .Annotations.summary }}
          *Details:* {{ .Annotations.description }}
          *Model:* {{ .Labels.model_version }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}
        actions:
          - type: button
            text: 'ML Dashboard'
            url: '${GRAFANA_URL}/d/ml-dashboard'
    
    email_configs:
      - to: 'ml-team@company.com'
        subject: '[ML Alert] Model Performance Issue'

  - name: 'devops-team'
    slack_configs:
      - api_url: '${DEVOPS_SLACK_WEBHOOK_URL}'
        channel: '#infrastructure'
        color: '#ff9900'
        title: '‚öôÔ∏è Infrastructure Alert'
        text: |
          {{ range .Alerts }}
          *Service:* {{ .Labels.service }}
          *Issue:* {{ .Annotations.summary }}
          *Details:* {{ .Annotations.description }}
          {{ end }}
        actions:
          - type: button
            text: 'Infrastructure Dashboard'
            url: '${GRAFANA_URL}/d/infrastructure-dashboard'
    
    email_configs:
      - to: 'devops@company.com'
        subject: '[Infrastructure] Service Alert'

  - name: 'engineering-team'
    slack_configs:
      - api_url: '${ENGINEERING_SLACK_WEBHOOK_URL}'
        channel: '#engineering'
        color: 'good'
        title: 'üîß Application Performance Alert'
        text: |
          {{ range .Alerts }}
          *Application:* {{ .Labels.service }}
          *Issue:* {{ .Annotations.summary }}
          *Impact:* {{ .Annotations.description }}
          {{ end }}

  - name: 'business-team'
    email_configs:
      - to: 'business-team@company.com'
        subject: '[Business Metrics] Performance Alert'
        body: |
          Business metrics alert:
          
          {{ range .Alerts }}
          Metric: {{ .Annotations.summary }}
          Impact: {{ .Annotations.description }}
          {{ end }}

# Inhibition rules - prevent spam
inhibit_rules:
  # Inhibit duplicate alerts
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
  
  # Inhibit service-specific alerts when the whole service is down
  - source_match:
      alertname: 'SecurityServiceDown'
    target_match_re:
      service: 'ml-risk-engine|security-monitor'
    equal: ['instance']

# Mute configuration for maintenance windows
mute_time_intervals:
  - name: 'maintenance-window'
    time_intervals:
      - times:
          - start_time: '02:00'
            end_time: '04:00'
        weekdays: ['sunday']
        months: ['1:12']

# High availability configuration
ha:
  listen: 0.0.0.0:9094
  advertise: '${ALERTMANAGER_CLUSTER_ADDR}:9094'
  peers: []